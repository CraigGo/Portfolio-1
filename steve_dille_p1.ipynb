{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. Notice that we are splitting the data into training, development, and test. We also have a small subset of the training data called mini_train_data and mini_train_labels that you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (70000, 784)\n",
      "label shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the digit data either from mldata.org, or once downloaded to data_home, from disk. The data is about 53MB so this cell\n",
    "# should take a while the first time your run it.\n",
    "\n",
    "X, Y = fetch_openml('mnist_784', return_X_y=True , cache=False)\n",
    "Y = Y.astype(int)\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print ('data shape: ', X.shape)\n",
    "print ('label shape:', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Create a 10x10 grid to visualize 10 examples of each digit. Python hints:\n",
    "\n",
    "- plt.rc() for setting the colormap, for example to black and white\n",
    "- plt.subplot() for creating subplots\n",
    "- plt.imshow() for rendering a matrix\n",
    "- np.array.reshape() for reshaping a 1D feature vector into a 2D matrix (for rendering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P1(num_examples=10):\n",
    "\n",
    "    # Function to take a parameter of n = number of example images to print from MINST dataset and then\n",
    "    # print an n x n matrix of sample images.\n",
    "      \n",
    "    column = num_examples\n",
    "    row = num_examples\n",
    "    image_count = 0\n",
    "    \n",
    "    # loop for the rows.  current_digit is the current image being printed from 0 to num_examples\n",
    "    for current_digit in range (row):                       \n",
    "        k = 0\n",
    "        \n",
    "     # loop for the columns to print per row. Keep reading until you find current_digit then print.   \n",
    "        for i in range (column):                               \n",
    "            while mini_train_labels[k] != current_digit:   \n",
    "                k += 1                                         \n",
    "            else:\n",
    "                image = mini_train_data[k].reshape(28, 28) \n",
    "                plt.subplot(row, column, image_count+1)    \n",
    "                plt.imshow(image, cmap='gray')             \n",
    "                plt.axis('off')                            \n",
    "                image_count += 1\n",
    "                k += 1 \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "P1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Evaluate a K-Nearest-Neighbors model with k = [1,3,5,7,9] using the mini training set. Report accuracy on the dev set. For k=1, show precision, recall, and F1 for each label. Which is the most difficult digit?\n",
    "\n",
    "- KNeighborsClassifier() for fitting and predicting\n",
    "- classification_report() for producing precision, recall, F1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Data Set Accuracy for Varying Levels of k\n",
      "\n",
      "Accuracy with k = 1 is 0.884\n",
      "Accuracy with k = 3 is 0.876\n",
      "Accuracy with k = 5 is 0.882\n",
      "Accuracy with k = 7 is 0.877\n",
      "Accuracy with k = 9 is 0.875\n",
      "\n",
      "Classification Report with k=1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       106\n",
      "           1       0.89      0.98      0.93       118\n",
      "           2       0.90      0.79      0.84       106\n",
      "           3       0.93      0.87      0.90        97\n",
      "           4       0.91      0.85      0.88        92\n",
      "           5       0.86      0.88      0.87        88\n",
      "           6       0.92      0.92      0.92       102\n",
      "           7       0.85      0.94      0.89       102\n",
      "           8       0.83      0.77      0.80        94\n",
      "           9       0.80      0.86      0.83        95\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.89      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def P2(k_values):\n",
    "\n",
    "# Function to train a KNN Classifier on mini-training data set and report accuracy on a dev data set \n",
    "# for a parameter of k_values passed into P2 (k=1,3,5,7,9 in this case). Print a classification report for K=1\n",
    "    k=1\n",
    "    print (\"Development Data Set Accuracy for Varying Levels of k\")\n",
    "    print()\n",
    "    \n",
    "    # For each K value, set K, fit the model and score the model (using dev_data_)\n",
    "    for k in k_values:\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)                               \n",
    "        classifier.fit(mini_train_data, mini_train_labels)                             \n",
    "        print (\"Accuracy with k =\",k, \"is\", classifier.score(dev_data, dev_labels)) \n",
    "\n",
    "    # Print a classificaion report for K=1 with dev_data    \n",
    "    k=1\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)                                   \n",
    "    classifier.fit(mini_train_data, mini_train_labels)                                 \n",
    "    y_pred = classifier.predict(dev_data)                                           \n",
    "    print()\n",
    "    print (\"Classification Report with k=1\")\n",
    "    print(classification_report(dev_labels, y_pred))                                   \n",
    "\n",
    "    \n",
    "### MAIN ###\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "P2(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:With K = 1 the most difficult digit to classify is 8.  The f-1 score is the lowest for 8.  83% of the time, the classifier is not labeling digits as an 8 which are not an 8 (precision).  Only 77% of the time, it is correctly classifying the digit 8 as an 8 from the data set (recall).  With digit 9, I do note that the precision is the lowest of any digit, but the recall is much higher than the digit 8, so overall it performs better.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Using k=1, report dev set accuracy for the training set sizes below. Also, measure the amount of time needed for prediction with each training size.\n",
    "\n",
    "- time.time() gives a wall clock value you can use for timing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size    Accuracy    Prediction Time (seconds)\n",
      "       100            0.702           0.13068414\n",
      "       200            0.791           0.24951720\n",
      "       400            0.811           0.49939013\n",
      "       800            0.866           1.10038185\n",
      "      1600            0.905           2.09145093\n",
      "      3200            0.927           4.25234294\n",
      "      6400            0.939           8.64120197\n",
      "     12800            0.952          16.05651999\n",
      "     25000            0.962          32.44500709\n"
     ]
    }
   ],
   "source": [
    "def P3(train_sizes, accuracies):\n",
    "\n",
    "# Function to measure prediction accuracy and prediction time at various training sizes.\n",
    "# Accepts the training_sizes and accumulates a list of accuracies to be used later.  \n",
    "\n",
    "    k=1\n",
    "    print(\"Training Set Size   \", \"Accuracy   \", \"Prediction Time (seconds)\")\n",
    "    for i in train_sizes:\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)                               \n",
    "        classifier.fit(train_data[0:i], train_labels[0:i])\n",
    "        start_time = time.time() \n",
    "        y_pred = classifier.predict(dev_data) \n",
    "        end_time = time.time()\n",
    "        score = classifier.score(dev_data, dev_labels)\n",
    "        print('{:10} {:16.3f} {:20.8f}'.format(i, score, end_time - start_time))\n",
    "        accuracies.append(score)\n",
    "\n",
    "    return\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n",
    "accuracies = []\n",
    "P3(train_sizes, accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above report is self-explanatory.  The accuracy increases as we have more data to train on as expected.  The prediction time is increasing with data size in most cases close to linearly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a regression model that predicts accuracy from training size. What does it predict for n=60000? What's wrong with using regression here? Can you apply a transformation that makes the predictions more reasonable?\n",
    "\n",
    "- Remember that the sklearn fit() functions take an input matrix X and output vector Y. So each input example in X is a vector, even if it contains only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression score (R2) of a linear model that predicts accuracy from training size is 0.42.\n",
      "For training size=60000, the predicted accuracy of this model is 124%.\n",
      "\n",
      "The R2 of a linear model that predicts accuracy from log of training size is: 0.91.\n",
      "For training size=60000, the predicted accuracy of this model is 103%.\n"
     ]
    }
   ],
   "source": [
    "def P4():\n",
    "\n",
    "# Linear regression function to predict the accuracy of a KNN classifier from training data size.\n",
    "# train_sizes and accuracies computed in the prior cells\n",
    "\n",
    "    # Make X a vector for linear regression method\n",
    "    train_sizes_np = []\n",
    "    for i in range (0, len(train_sizes)):\n",
    "        train_sizes_np.append([train_sizes[i]])\n",
    "\n",
    "    X = np.array(train_sizes_np)\n",
    "    y = np.array(accuracies)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    print(\"The regression score (R2) of a linear model that predicts accuracy from training size is {:.2f}.\".format(reg.score(X, y)))\n",
    "    print(\"For training size=60000, the predicted accuracy of this model is {:.0f}%.\".format(reg.predict(np.array([[60000]]))[0]*100))\n",
    "\n",
    "    # Transform the model to predict on the log of the training data size and accuracies\n",
    "    reg.fit(np.log(X), y)\n",
    "    print()\n",
    "    print(\"The R2 of a linear model that predicts accuracy from log of training size is: {:.2f}.\".format(reg.score(np.log(X), y)))\n",
    "    print(\"For training size=60000, the predicted accuracy of this model is {:.0f}%.\".format(reg.predict(np.array([[np.log(60000)]]))[0]*100))\n",
    "    \n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "P4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The linear regression model does not work very well for predicting accuracy with an R2 of .42 and accuracy of 124%.  This is due to the fact that the relationship between sample size and accuracy is not linear.  This is shown in the first graph below.  The model can be made more predictive by transforming the independent variable with a log function.  This compacts the data more and gives us a much closer fit as can be seen from the R2 of .91 and accuracy score of 103%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the original data\n",
    "plt.title(\"Accuracy by Training Data Size\")\n",
    "plt.plot(train_sizes, accuracies, 'ro')\n",
    "plt.show()\n",
    "\n",
    "# Plot the log data\n",
    "plt.title(\"Accuracy by Log(Training Data Size)\")\n",
    "plt.plot(np.log(train_sizes), accuracies, 'ro')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tried other techniques to improve the accuracy of the regression but none worked.  In particular, I tried log odds and logisitic regression techniques as shown below in these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y Axis Values for Test Training Size Differences and Accuracies\n",
      "[[100], [100], [200], [400], [800], [1600], [3200], [6400], [12200]]\n",
      "[0.702, 0.791, 0.811, 0.866, 0.905, 0.927, 0.939, 0.952, 0.962]\n",
      "\n",
      "The regression score (R2) of a linear model that predicts accuracy from training size X axis differences is 0.42.\n",
      "For training size=60000, the accuracy of this model is 168%.\n",
      "\n",
      "X and Y Axis Values for Test Training Sizes and Accuracy Differences\n",
      "[[100], [200], [400], [800], [1600], [3200], [6400], [12800], [25000]]\n",
      "[0.702, 0.08900000000000008, 0.020000000000000018, 0.05499999999999994, 0.039000000000000035, 0.02200000000000002, 0.0119999999999999, 0.013000000000000012, 0.010000000000000009]\n",
      "\n",
      "The regression (R2) of a linear model that predicts accuracy from training size with Y axis differences is 0.09.\n",
      "For training size=60000, the accuracy of this model is -34%.\n",
      "\n",
      "X and Y Axis Values for Test Training Sizes and Accuracy/(1-Accuracy)\n",
      "[[100], [200], [400], [800], [1600], [3200], [6400], [12800], [25000]]\n",
      "[0.8568399175204064, 1.3309637158028431, 1.456521039055771, 1.8660451086115237, 2.2540580520993854, 2.541494124417465, 2.7339416150349507, 2.9873640238834733, 3.23142829093932]\n",
      "\n",
      "The regression score (R2) of a linear model that predicts accuracy from training size is 0.61.\n",
      "For training size=60000, the accuracy of this model is 628%.\n"
     ]
    }
   ],
   "source": [
    "def p4test():\n",
    "# Make X a vector for linear regression method  \n",
    "    \n",
    "    # I tried using the distance between the X axis points instead of the raw value to predict accuracy\n",
    "    accuracies_np = accuracies\n",
    "    train_sizes_np = [[train_sizes[0]]]\n",
    "    for i in range (1, len(train_sizes)):\n",
    "        train_sizes_np.append([train_sizes[i] - train_sizes[i-1]])\n",
    "    \n",
    "    # print values\n",
    "    print (\"X and Y Axis Values for Test Training Size Differences and Accuracies\")\n",
    "    print(train_sizes_np)\n",
    "    print(accuracies_np)\n",
    "    print()\n",
    "\n",
    "    X = np.array(train_sizes_np)\n",
    "    y = np.array(accuracies_np)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    print(\"The regression score (R2) of a linear model that predicts accuracy from training size X axis differences is {:.2f}.\".format(reg.score(X, y)))\n",
    "    print(\"For training size=60000, the accuracy of this model is {:.0f}%.\".format(reg.predict(np.array([[60000]]))[0]*100))\n",
    "    print()\n",
    " \n",
    "\n",
    "    # I tried using the distance between the X axis points instead of the raw value to predict accuracy  \n",
    "    train_sizes_np = []\n",
    "    for i in range (0, len(train_sizes)):\n",
    "        train_sizes_np.append([train_sizes[i]])\n",
    "        \n",
    "    accuracies_np = [accuracies[0]]\n",
    "    for i in range (1, len(accuracies)):\n",
    "        accuracies_np.append(accuracies[i] - accuracies[i-1]) \n",
    "\n",
    "    # print values\n",
    "    print (\"X and Y Axis Values for Test Training Sizes and Accuracy Differences\")\n",
    "    print(train_sizes_np)\n",
    "    print(accuracies_np)\n",
    "    print()\n",
    "\n",
    "    X = np.array(train_sizes_np)\n",
    "    y = np.array(accuracies_np)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    print(\"The regression (R2) of a linear model that predicts accuracy from training size with Y axis differences is {:.2f}.\".format(reg.score(X, y)))\n",
    "    print(\"For training size=60000, the accuracy of this model is {:.0f}%.\".format(reg.predict(np.array([[60000]]))[0]*100))\n",
    "    print()    \n",
    "\n",
    "    \n",
    "    # I tried using the log of the predicted accuracy over (1 - predicted accuracy) instead of the raw value to predict accuracy  \n",
    "    accuracies_np = []\n",
    "    for i in range (0, len(accuracies)):\n",
    "        accuracies_np.append(np.log((accuracies[i]/(1-accuracies[i])))) \n",
    "        \n",
    "    # print values\n",
    "    print (\"X and Y Axis Values for Test Training Sizes and Accuracy/(1-Accuracy)\")\n",
    "    print(train_sizes_np)\n",
    "    print(accuracies_np)\n",
    "    print()\n",
    "    \n",
    "    X = np.array(train_sizes_np)\n",
    "    y = np.array(accuracies_np)\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "\n",
    "    print(\"The regression score (R2) of a linear model that predicts accuracy from training size is {:.2f}.\".format(reg.score(X, y)))\n",
    "    print(\"For training size=60000, the accuracy of this model is {:.0f}%.\".format(reg.predict(np.array([[60000]]))[0]*100))\n",
    "\n",
    "p4test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Fit a 1-NN and output a confusion matrix for the dev data. Use the confusion matrix to identify the most confused pair of digits, and display a few example mistakes.\n",
    "\n",
    "- confusion_matrix() produces a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONFUSION MATRIX FOR 1-NN MODEL RUN WITH DEVELOPMENT DATASET\n",
      "\n",
      "[[101   0   1   0   0   0   1   1   2   0]\n",
      " [  0 116   1   0   0   0   0   0   1   0]\n",
      " [  1   4  84   2   2   0   2   4   6   1]\n",
      " [  0   2   0  84   0   6   0   2   3   0]\n",
      " [  0   0   1   0  78   0   0   2   0  11]\n",
      " [  2   0   0   1   1  77   5   0   2   0]\n",
      " [  1   2   1   0   1   2  94   0   1   0]\n",
      " [  0   1   1   0   0   0   0  96   0   4]\n",
      " [  1   5   4   3   1   3   0   1  72   4]\n",
      " [  0   1   0   0   3   2   0   7   0  82]]\n",
      "\n",
      "Here are three example 4 digits that were classified as the digit 9:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACECAYAAACJbXCEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACFBJREFUeJzt3U2IzV8cx/Hf1RRiWEgeNkgpz0JoFh6aDWGhaBZSQiiF0iwNE6sxXQsLdpIsaaKRIk8LGybkYUEhCQ1FlOfr9185nXP+c39z753fw/387vu1+p7Onfs7//+v+XZ85zwUwjAMAAB6hmU9AABAbUjgACCKBA4AokjgACCKBA4AokjgACCKBA4AokjgACCqKc2HFQoFdg3ViTAMC3F9F++1fvBe86nce2UGDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiUj2NEADicOTIERN/+fLF6SsWiyYulUqpjSkLzMABQBQJHABEkcABQFQhDNO7dCOJGz5GjhzptMeOHWvi9+/fx/24QS1atMjEN2/edPo6OztN3N3dndaQBsTNLdFWrlzptG/cuGFi+z0GQRAcPnw4hRFVJq/v1f69CoIg6OnpMfGkSZOcvsmTJ5u4v78/2YGlhBt5ACBnSOAAIEp+GeHu3bud9rFjx0zc1JT+f96sWbNM7Jd3oOPQoUM19dVTOSVP9u7d67T9skmjYgYOAKJI4AAgigQOAKIka+Djxo0z8Z49ezIcCfJiKMtp7Zo4NfD42H9DmjZtWtnPvXjxwmn/+PEjsTHVG2bgACCKBA4AoiRLKPaurKlTpzp9T58+TXk0lTtz5kzWQ2ho/u7KqOWAyF5ra6uJW1payn7uzp07Tts/nTDPmIEDgCgSOACIIoEDgCjJGvirV69M/PHjR6fPr4nXk40bN5r45MmTGY6kMfk1b78mHgd/GSHLCmvX0dFh4kLBPYzv2bNnJm5vb098LM3NzU77z58/Jv7+/Xvizy+HGTgAiCKBA4AoyRKKXSYZP36803fr1q2UR+OylzH6/7QaNWpU2sNpePZFDNWUTPzLOCr9Wf/nULk1a9Y4bXu58Ldv35y+rq4uE3/48CHx8djPCwK3hLN161an7+vXr4mMZyDMwAFAFAkcAESRwAFAlGQN3F5G6Ne/7t69m/JoXFE38tg1tawvNc4rf9lerUsF/YuL7b+tsAU/PvYFxEePHi37uatXrzrt06dPJzamf2bPnm1i+/c6CIJg5syZJl62bJnT5481SczAAUAUCRwAREmWUOxdUSNGjHD6onY72qWXLDx58iTT5+dF1KmCcZVMfJWWTfzns6wwmn3i4Pz5850++2KGNEqO69atc9o7d+4s+9lPnz6Z+N27d4mNaTDMwAFAFAkcAESRwAFAlGQNvK+vz8S9vb1OX1tbm4kvXrzo9M2bNy/ZgQ3i9evXmT4/L+zt8UNh16fjOkWQmnc0/7TQgwcPlv2sfeLf58+fnb5NmzaZeMqUKRU/f/HixU67v7/fxH7Nu6mpfHq8cOGCiR8/flzx8+PGDBwARJHAAUCUZAnFtmPHDqc9ZswYEy9fvtzps3dT1fPlx/j/crw4yiarVq1y2kmUOyihRNu+fbvTnj59etnP2r/Ljx49qul5w4a5c9S/f//W9D12qSUIgmDXrl01fU/cmIEDgCgSOACIIoEDgCj5Grh/683ly5dN7G+NvX79uolXr17t9D148CCW8Rw4cMDE/kWsa9euNXGpVHL6jh8/Hsvzldl177iWCpb7/oHatlpPHAzD0GnbdXfq4/9fRuj//7LZ9eqoz0V58+aN0/ZPLz1//ryJFyxY4PRt2LBhyM9PGjNwABBFAgcAUSRwABAlXwP32UfILlmyxOnbsmWLiS9duuT02TdL37592+n7/fu3if1bdmbMmOG0hw8fbmK/bmavS//165fTRw289qNgK5XGTTrUuaPt37/fad+7d8/E/t+lisXikJ/3/Plzpx11pPT9+/eH/Ly0MQMHAFEkcAAQVUhzeUyhUEh1LY5dzgiCIDhx4oSJt23bVvbnokooo0ePdvqWLl1a8XjsE9Xmzp3r9KV9q0cYhoXBP1WZuN6rXULxyx1Jl1eS4i8lTVo9vlcVfgnF/h31t9LblzGnodx7ZQYOAKJI4AAgigQOAKJyt4zQ9vPnT6e9b98+E/vLCNvb203sH0Nr1zH9vxn4teuXL1+auKWlxemzt+tneZN1vbKX4FWz7T3q5yp9nq+a72G7PLLCDBwARJHAAUBUrksoPvvkQr+Ecu3aNRM3Nzc7fVElFH9H5fr1603sl1CuXLlS5Ygbl3+pcFSZpNYLiKO+I65SDHT4Sz7tdtrLQSvFDBwARJHAAUAUCRwARDVUDTyKXR/3b/mpxtmzZ03c1dXl9K1YscLE3d3dNT+jEdl15qxrzp2dnZk+H8no7e112nPmzDExN/IAAGJFAgcAUZRQEuT/s8s+uXDz5s1O37lz51IZEwbml2XSuPwB9WUopdOsMAMHAFEkcAAQRQIHAFG5vpEna2/fvnXaEyZMMPHDhw+dvoULF6Yypn+4uSWav7U+qiZeT9usea+18/8O1dbWZuJSqeT09fT0DPi5pHAjDwDkDAkcAESxjBAYQDXLCu1ySxwnIyIbxWLRaU+cONHE/umU9gXlWWIGDgCiSOAAIIoEDgCiqIEn6NSpU07brqN1dHSkPBpUw6+B13pxMnT09fU57dbW1oxGUjlm4AAgigQOAKLYidmg2LGXT7zXfGInJgDkDAkcAESRwAFAFAkcAESRwAFAFAkcAESRwAFAFAkcAESRwAFAFAkcAESlupUeABAfZuAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIIoEDgCiSOAAIOo/8/NJLQYpnv0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are three example 9 digits that were classified as the digit 4:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P5():\n",
    "\n",
    "    #Function to create a confusion matrix of digits from our dev data, ID the most confused digits and print 3 examples.\n",
    "\n",
    "    # Fit a 1-NN model\n",
    "    k=1\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)                            \n",
    "    classifier.fit(mini_train_data, mini_train_labels)                            \n",
    "    y_pred = classifier.predict(dev_data)                                           \n",
    "\n",
    "    # Output a confusion matrix for the dev_data\n",
    "    print ()\n",
    "    print (\"CONFUSION MATRIX FOR 1-NN MODEL RUN WITH DEVELOPMENT DATASET\")\n",
    "    print ()\n",
    "    print (confusion_matrix(dev_labels, y_pred, labels=[0,1,2,3,4,5,6,7,8,9,]))     \n",
    "    print()\n",
    "\n",
    "    # We can see from the confusion matrix that 4s are being misclassified as 9s most commonly.\n",
    "    # Capture the list of confused 4s\n",
    "    list_of_confused_4 = []\n",
    "    for i in range (0, len(dev_labels)):                                            \n",
    "        if dev_labels[i] == 4 and y_pred [i] == 9:\n",
    "            list_of_confused_4.append(i)\n",
    "\n",
    "    # Print 3 examples of confused digits        \n",
    "    print (\"Here are three example 4 digits that were classified as the digit 9:\")\n",
    "\n",
    "    for i in range (3):                                                            \n",
    "        image = dev_data[list_of_confused_4[i]].reshape(28, 28)                  \n",
    "        plt.subplot(1, 3, i+1)                                              \n",
    "        plt.imshow(image, cmap='gray')                                            \n",
    "        plt.axis('off')                                                            \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Let's also look at the corresponding 9 digits confused as 4s\n",
    "    list_of_confused_9 = []\n",
    "    for i in range (0, len(dev_labels)):                                           \n",
    "        if dev_labels[i] == 9 and y_pred [i] == 4:\n",
    "            list_of_confused_9.append(i)\n",
    "\n",
    "    # Print 3 examples of confused digits\n",
    "    print()\n",
    "    print (\"Here are three example 9 digits that were classified as the digit 4:\")\n",
    "\n",
    "    for i in range (3):                                                            \n",
    "        image = dev_data[list_of_confused_9[i]].reshape(28, 28)                    \n",
    "        plt.subplot(1, 3, i+1)                                                     \n",
    "        plt.imshow(image, cmap='gray')                                             \n",
    "        plt.axis('off')                                                            \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the confusion matrix, the most confused pair of digits are 4 and 9. 4 is confused for the digit 9 eleven times and 9 is confused for the digit 4 three times for a total of 14 inaccurate predictions on these digits.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian -- that is, the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur by just using the 8 neighboring pixels: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values. Try applying your blur filter in 3 ways:\n",
    "- preprocess the training data but not the dev data\n",
    "- preprocess the dev data but not the training data\n",
    "- preprocess both training and dev data\n",
    "\n",
    "Note that there are Guassian blur filters available, for example in scipy.ndimage.filters. You're welcome to experiment with those, but you are likely to get the best results with the simplified version I described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier with original data\n",
      "Accuracy with k = 1 is 0.884\n",
      "\n",
      "KNN classifier with blurred dev data only\n",
      "Accuracy with k = 1 is 0.868\n",
      "\n",
      "KNN classifier with blurred training data only\n",
      "Accuracy with k = 1 is 0.908\n",
      "\n",
      "KNN classifier with blurred training and dev data\n",
      "Accuracy with k = 1 is 0.904\n"
     ]
    }
   ],
   "source": [
    "def knn_classifier (k, train_data, train_labels, test_data, test_labels):\n",
    "\n",
    "    # KNN classifer function that accepts k, the training data and labels and test data and labels and prints accuracy.\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)                                   \n",
    "    classifier.fit(train_data, train_labels)                                           \n",
    "    print (\"Accuracy with k =\",k, \"is\", classifier.score(test_data, test_labels))        \n",
    "    return\n",
    "\n",
    "def blur_function (row, data_set):                             \n",
    "\n",
    "    # This is a function to blur an image by averaging the surround pixels. It accepts the dataset we will blur as a parameter and the current\n",
    "    # row of the image we are processing from the file (0-999).  We reshape that 784 pixel row in this function to 28x28 and average pixel weights.\n",
    "    # The function returns a row in the original format of 784 pixels per row.\n",
    "    \n",
    "    # Performance note - I wrote this function to be intuitive and easy to understand with simple ifs doing special case averaging\n",
    "    # where we do not have 8 surrounding pixels to average.  After dealing with special cases, we drop into the most common case for rows\n",
    "    # 1-26 and columns 1-26.  Since our data sizes are small, this works just fine.  However, if we wanted to increase data size\n",
    "    # a simple fix to eliminate running so many conditional ifs is to move the last averaging line to the beginning and place it under\n",
    "    # an if to determine you are not in a special case situation which is the case 90% of the time.  It will eliminate much processing but is\n",
    "    # to me not quite as intuitive.  \n",
    "    \n",
    "    dataset_28 = data_set.reshape(1000,28,28)\n",
    "    data_row = np.empty_like (dataset_28[row]) \n",
    "\n",
    "    # i is the row number and j is the column in a 28x28 matrix\n",
    "    for i in range (0, 28):\n",
    "        for j in range (0,28):\n",
    "  \n",
    "            # These first 3 ifs deal with averaging the special cases of the first row and the two corners in the first row\n",
    "            if i == 0 and j == 0:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i,j+1] + dataset_28[row,i+1,j] + dataset_28[row,i+1,j+1])/4\n",
    "                continue\n",
    "            if i == 0 and j == 27:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i,j-1] + dataset_28[row,i+1,j] + dataset_28[row,i+1,j-1])/4\n",
    "                continue\n",
    "            if i == 0:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i,j-1] + dataset_28[row,i,j+1] + dataset_28[row,i+1,j] + dataset_28[row,i+1,j-1] + dataset_28[row,i+1,j+1])/6\n",
    "                continue\n",
    "\n",
    "            # These second 3 ifs deal with averaging the special cases of the last row and the two corners in the last row   \n",
    "            if i == 27 and j == 0:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i,j+1] + dataset_28[row,i-1,j] + dataset_28[row,i-1,j+1])/4\n",
    "                continue\n",
    "            if i == 27 and j == 27:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i,j-1] + dataset_28[row,i-1,j] + dataset_28[row,i-1,j-1])/4\n",
    "                continue\n",
    "            if i == 27:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i,j-1] + dataset_28[row,i,j+1] + dataset_28[row,i-1,j] + dataset_28[row,i-1,j-1] + dataset_28[row,i-1,j+1])/6\n",
    "                continue\n",
    "\n",
    "            # These 2 ifs deal with averaging the special cases of the non-corners of the first column and the last column  \n",
    "            if j == 0:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i-1,j] + dataset_28[row,i-1,j+1] + dataset_28[row,i,j+1] + dataset_28[row,i+1,j+1] + dataset_28[row,i+1,j])/6\n",
    "                continue\n",
    "            if j == 27:\n",
    "                data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i-1,j] + dataset_28[row,i-1,j-1] + dataset_28[row,i,j-1] + dataset_28[row,i+1,j-1] + dataset_28[row,i+1,j])/6\n",
    "                continue\n",
    "\n",
    "            # For everything else in the middle of the matrix, we average the 8 surrounding pixels, the target pixel and divide by 9\n",
    "            data_row[i,j] = (dataset_28[row,i,j] + dataset_28[row,i-1,j] + dataset_28[row,i-1,j-1] + dataset_28[row,i-1,j+1] + dataset_28[row,i,j-1] + dataset_28[row,i,j+1] + dataset_28[row,i+1,j] + dataset_28[row,i+1,j-1] + dataset_28[row,i+1,j+1])/9\n",
    "\n",
    "    return data_row.reshape(784)\n",
    "\n",
    "                                  \n",
    "                                  \n",
    "def gaussian_blur (num_rows, num_cols, data_set):\n",
    "    \n",
    "    ### Function accepts a data set of images and returns a blurred version of the data set.  parameters are the data set,\n",
    "    ### number of rows and number of columns.\n",
    "    \n",
    "    blur_data = np.empty_like (data_set)       # define a new blur_data numpy array and copy the given data set\n",
    "    blur_data[:] = data_set\n",
    "    for row in range (0, num_rows):         # Process the number of rows given in the data set\n",
    "        blur_data[row] = blur_function (row, data_set)  # send in the row and the full data set for surrounding rows\n",
    "                                                                    \n",
    "    return blur_data\n",
    "\n",
    "\n",
    "### MAIN\n",
    "\n",
    "# This program smooths an image by blurring to improve model predictive accuracy. The value of a particular pixel\n",
    "# is estimated as the weighted combination of the original value and the values around it above, below, left and right.  \n",
    "# The program reports accuracy improvements for blurring dev data only, training data only and both dev and training data.\n",
    "\n",
    "rows = 1000\n",
    "columns = 784\n",
    "k=1\n",
    "\n",
    "# Run the KNN classifer and report accuracy on the original unblurred data\n",
    "\n",
    "print(\"KNN classifier with original data\")\n",
    "knn_classifier (k, mini_train_data, mini_train_labels, dev_data, dev_labels)\n",
    "\n",
    "# Run the KNN classifier on blurred development data only \n",
    "\n",
    "print()\n",
    "print(\"KNN classifier with blurred dev data only\")\n",
    "blur_dev = np.empty_like (dev_data)\n",
    "blur_dev = gaussian_blur (rows, columns, dev_data)\n",
    "\n",
    "knn_classifier (k, mini_train_data, mini_train_labels, blur_dev, dev_labels)\n",
    "\n",
    "# Run the KNN classifier on blurred training data only\n",
    "print()\n",
    "print(\"KNN classifier with blurred training data only\")\n",
    "\n",
    "blur_train = np.empty_like (mini_train_data)\n",
    "blur_train = gaussian_blur (rows, columns, mini_train_data)\n",
    "\n",
    "knn_classifier (k, blur_train, mini_train_labels, dev_data, dev_labels)\n",
    "\n",
    "# Run the KNN classifier on blurred training data and development data\n",
    "\n",
    "print()\n",
    "print(\"KNN classifier with blurred training and dev data\")\n",
    "\n",
    "knn_classifier (k, blur_train, mini_train_labels, blur_dev, dev_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:  This Blur filter is improving the accuracy when compared to the orignal KNN classifier.  But these results show that the filter must be applied to the training data to gain the performance improvements.  Just blurring the development data (or test data) without training the model to understand this makes performance worse.  Once the model is trained with blurred data, the improvement in accuracy is over 2%.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Fit a Naive Bayes classifier and report accuracy on the dev data. Remember that Naive Bayes estimates P(feature|label). While sklearn can handle real-valued features, let's start by mapping the pixel values to either 0 or 1. You can do this as a preprocessing step, or with the binarize argument. With binary-valued features, you can use BernoulliNB. Next try mapping the pixel values to 0, 1, or 2, representing white, grey, or black. This mapping requires MultinomialNB. Does the multi-class version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Accuracy Score (BernoulliNB) on Dev Data with Pixel Values Mapped to 0/1\n",
      "0.822\n",
      "\n",
      "Naive Bayes Classifier Accuracy Score (MultinomialNB) on Dev Data with Pixel Values Mapped to 0/1/2\n",
      "0.816\n"
     ]
    }
   ],
   "source": [
    "def P7():\n",
    "\n",
    "    # NB Classifier with binned data function.  The model shows binning mini_train_data into 0,1 bins and then into 3 bins.\n",
    "    # The results are reported.  \n",
    "    \n",
    "    X = mini_train_data\n",
    "    y = mini_train_labels\n",
    "    clf = BernoulliNB(alpha=0.5,binarize=0.5)\n",
    "    clf.fit(X, y)\n",
    "    print(\"Naive Bayes Classifier Accuracy Score (BernoulliNB) on Dev Data with Pixel Values Mapped to 0/1\")\n",
    "    print(clf.score(dev_data, dev_labels))\n",
    "\n",
    "    # Preprocess Training Data divide into bins by values of <=1/3, <=2/3 or other \n",
    "    mini_train_bin = np.empty_like (mini_train_data)\n",
    "    for i in range (0, len(mini_train_data)):\n",
    "        for j in range (0,784):\n",
    "            if mini_train_data[i,j] <= 1/3:\n",
    "                mini_train_bin[i,j] = 0\n",
    "                continue\n",
    "            if mini_train_data[i,j] > 1/3 and mini_train_data[i,j] <= 2/3:\n",
    "                mini_train_bin[i,j] = 1\n",
    "                continue\n",
    "            else:\n",
    "                mini_train_bin[i,j] = 2        \n",
    "\n",
    "     # Preprocess Dev Data divide into bins by values of <=1/3, <=2/3 or other \n",
    "    dev_data_bin = np.empty_like (dev_data)\n",
    "    for i in range (0, len(dev_data)):\n",
    "        for j in range (0,784):\n",
    "            if dev_data[i,j] <= 1/3:\n",
    "                dev_data_bin[i,j] = 0\n",
    "                continue\n",
    "            if dev_data[i,j] > 1/3 and dev_data[i,j] <= 2/3:\n",
    "                dev_data_bin[i,j] = 1\n",
    "                continue\n",
    "            else:\n",
    "                dev_data_bin[i,j] = 2        \n",
    "                \n",
    "    X = mini_train_bin\n",
    "    y = mini_train_labels\n",
    "    clf = MultinomialNB(alpha=.5)\n",
    "    clf.fit(X, y)\n",
    "    print()\n",
    "    print(\"Naive Bayes Classifier Accuracy Score (MultinomialNB) on Dev Data with Pixel Values Mapped to 0/1/2\")\n",
    "    print(clf.score(dev_data_bin, dev_labels))\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The mulinomial model did not improve the accuracy with these settings and binning.  I do note that if I change binarize settings on the Bernoulli model to very low thresholds to determine when a pizel becomes a 1, that the performance decreases to the multinomial level.  The accuracy would appear to be related to the fact of whether the pixels have stronger color or not.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Use GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) in a Bernoulli NB model. What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n",
    "\n",
    "- Note that GridSearchCV partitions the training data so the results will be a bit different than if you used the dev data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial predicitions on dev_data with BernoulliNB Model and Alpha=0. Accuracy Score = 0.816\n",
      "\n",
      "\n",
      "Best Score for Varying Alpha Levels with BernoulliNB Model, mini_train data: Accuracy Score = 0.823\n",
      "Best Alpha Value to Choose on BernoulliNB for this Test: 0.01\n",
      "BernoulliNB Accuracy with Alpha=0 with Training Data on GridSearchCV Testing:  Accuracy Score = 0.804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "def P8(alphas):\n",
    "\n",
    "### Function uses GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) \n",
    "### in a Bernoulli NB model. Accepts as a parameter the values of alpha to test with as a dictionary.\n",
    "### mini_train_data and mini_train_labels are used.  \n",
    "\n",
    "    model = BernoulliNB(binarize=0.000001)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=alphas, cv=3)\n",
    "    grid.fit(mini_train_data, mini_train_labels)\n",
    "#    print(grid)\n",
    "\n",
    "# summarize the results of the grid search \n",
    "    print()\n",
    "    print(\"Best Score for Varying Alpha Levels with BernoulliNB Model, mini_train data:\", \"Accuracy Score =\", grid.best_score_)\n",
    "    print(\"Best Alpha Value to Choose on BernoulliNB for this Test:\", grid.best_estimator_.alpha)\n",
    "    results = grid.cv_results_ \n",
    "    print(\"BernoulliNB Accuracy with Alpha=0 with Training Data on GridSearchCV Testing: \", \"Accuracy Score =\", grid.cv_results_['mean_test_score'][0])\n",
    "    print()\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "# First fit a BernoulliNB model and produce predictions on dev_data with Alpha = 0\n",
    "X = mini_train_data\n",
    "y = mini_train_labels\n",
    "clf = BernoulliNB(alpha=0.0, binarize=0.000001)\n",
    "clf.fit(X, y)\n",
    "print(\"Initial predicitions on dev_data with BernoulliNB Model and Alpha=0.\", \"Accuracy Score =\", clf.score(dev_data, dev_labels))\n",
    "print()\n",
    "\n",
    "# Use GridSearchCV to determne the best Alpha Value\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = P8(alphas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:  The best setting for alpha is 0.01 as you achieve the best accuracy score at that setting.  With Alpha = 0 the accuracy is .804 which is less than the best accuracy score of 0.823 with alpha = 0.01.   This is as expected as theoretically, by increasing the Lidstone smoothing parameter, we are compensating more strongly for absent features negating the absence of a feature more vigorously.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) Try training a model using GuassianNB, which is intended for real-valued features, and evaluate on the dev data. You'll notice that it doesn't work so well. Try to diagnose the problem. You should be able to find a simple fix that returns the accuracy to around the same rate as BernoulliNB. Explain your solution.\n",
    "\n",
    "Hint: examine the parameters estimated by the fit() method, theta\\_ and sigma\\_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of GaussianNB with var_smoothing = 1e-09 is:  0.593\n",
      "\n",
      "Average Sigma Value for Digit 0 is 0.060693.\n",
      "Average Sigma Value for Digit 1 is 0.027791.\n",
      "Average Sigma Value for Digit 2 is 0.066256.\n",
      "Average Sigma Value for Digit 3 is 0.058298.\n",
      "Average Sigma Value for Digit 4 is 0.052561.\n",
      "Average Sigma Value for Digit 5 is 0.059837.\n",
      "Average Sigma Value for Digit 6 is 0.051897.\n",
      "Average Sigma Value for Digit 7 is 0.046266.\n",
      "Average Sigma Value for Digit 8 is 0.056812.\n",
      "Average Sigma Value for Digit 9 is 0.049561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:436: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:436: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:436: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:436: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:436: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:436: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:438: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.sigma_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "       estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'var_smoothing': [0.0, 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "\n",
      "GridSearchCV Best var_smoothing Recommendation and Accuracy Score Prediction on Training Data\n",
      "Best Score: 0.797\n",
      "Best var_smoothing: 0.1\n",
      "\n",
      "Accuracy Score of GaussianNB with var_smoothing = .1 is:  0.817\n",
      "<bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=0.1)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "def P9():\n",
    "\n",
    "    # Function to train a model using GuassianNB and evaluate it on the dev_data. \n",
    "    X = mini_train_data\n",
    "    y = mini_train_labels\n",
    "    clf = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "    clf.fit(X, y)\n",
    "    print(\"Accuracy Score of GaussianNB with var_smoothing = 1e-09 is: \", clf.score(dev_data, dev_labels))\n",
    "    print()\n",
    "\n",
    "    # We note that this model does not perform well.  Let's diagnose why by printing and looking at Sigmas.\n",
    "    for i in range(10):\n",
    "    #    print(\"Theta of \", i, \" \", clf.theta_[i])\n",
    "    #    print(\"sigma of \", i, \" \", clf.sigma_[i])\n",
    "\n",
    "        avg = 0\n",
    "        for j in range (0,784):\n",
    "            avg = avg + clf.sigma_[i][j]\n",
    "        avg = avg/784\n",
    "        print (\"Average Sigma Value for Digit {:1} is {:.6f}.\".format(i, avg))\n",
    "\n",
    "\n",
    "    # Use GridsearchCV to determine a better parameter value for var_smoothing to imporve the accuaracy since the sigmas are so low\n",
    "    var_smoothing = {'var_smoothing': [0.0, 0.0000000001, 0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}\n",
    "    model = GaussianNB(priors=None)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=var_smoothing)\n",
    "    grid.fit(mini_train_data, mini_train_labels)\n",
    "    print(grid)\n",
    "\n",
    "    # Summarize the results of GridSearchCV\n",
    "    print()\n",
    "    print(\"GridSearchCV Best var_smoothing Recommendation and Accuracy Score Prediction on Training Data\")\n",
    "    print(\"Best Score:\", grid.best_score_)\n",
    "    print(\"Best var_smoothing:\", grid.best_estimator_.var_smoothing)\n",
    "    print()\n",
    "\n",
    "    # Plug the best var_smoothing parameter of .1 back into GaussianNB to produce a comparable accuracy score\n",
    "    X = mini_train_data\n",
    "    y = mini_train_labels\n",
    "    clf = GaussianNB(priors=None, var_smoothing=1e-01)\n",
    "    clf.fit(X, y)\n",
    "    print(\"Accuracy Score of GaussianNB with var_smoothing = .1 is: \", clf.score(dev_data, dev_labels))\n",
    "    print(clf.get_params)\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "gnb = P9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: I trained a model using GuassianNB on mini-train data and and evaluated on the dev data. The accuracy is only around 59%. If you examine the sigmas, of the data, the standard deviation is extremely small around the blank spaces of the images.  If we smooth this data we may get a better result.  By using GridSearchCV to estimate potentially a better var_smoothing parameter, I learned that by changing smoothing from 1e-09 to 1e-01, I could return the model to about the same accuracy rate (81.7%) as the BernoulliNB model results in problem 8 above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) Because Naive Bayes is a generative model, we can use the trained model to generate digits. Train a BernoulliNB model and then generate a 10x20 grid with 20 examples of each digit. Because you're using a Bernoulli model, each pixel output will be either 0 or 1. How do the generated digits compare to the training digits?\n",
    "\n",
    "- You can use np.random.rand() to generate random numbers from a uniform distribution\n",
    "- The estimated probability of each pixel is stored in feature\\_log\\_prob\\_. You'll need to use np.exp() to convert a log probability back to a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 200 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P10(num_examples):\n",
    "\n",
    "    #Fit Naive Bayes Classifier from mini_train_data and predict on dev_data\n",
    "\n",
    "    X = mini_train_data\n",
    "    y = mini_train_labels\n",
    "    clf = BernoulliNB(alpha=0.5,binarize=0.000001)\n",
    "    clf.fit(X, y)\n",
    "    y_predict = clf.predict(dev_data)\n",
    "\n",
    "    # Build grid for each of 10 digits\n",
    "    for i in range(10):\n",
    "        for j in range(num_examples):\n",
    "            # Process each digit (0-9) X 20 of them\n",
    "            matrix = np.exp(clf.feature_log_prob_[i])\n",
    "\n",
    "            # Go through each probability matrix item (k) and compare each pixel with a random number n.\n",
    "            # if probability greater than n set the pixel to 1, else 0\n",
    "            for k, pixel_prob in enumerate(matrix):\n",
    "                n = np.random.rand()\n",
    "                if pixel_prob > n:\n",
    "                    matrix[k] = 1\n",
    "                else:\n",
    "                    matrix[k] = 0\n",
    "\n",
    "            #  Plot each digit\n",
    "            plt.subplot(10, 20, (i*20) + (j+1))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(matrix.reshape(28,28), cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "### MAIN ###\n",
    "\n",
    "P10(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: How do the generated digits compare to the training digits?  The generated digits are blurier than the training digits.  This is because we are applying even greater levels of uncertainty to the predicition of each pixel (which is in itself, already uncertain).  We are using a random number generator and deciding if a pixel should be turned on if it's value is greater than the random value from the generator.  This increases noise in the predicition and lowers the quality.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Remember that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior and accuracy.\n",
    "\n",
    "Train a BernoulliNB model with a reasonable alpha value. For each posterior bucket (think of a bin in a histogram), you want to estimate the classifier's accuracy. So for each prediction, find the bucket the maximum posterior belongs to and update the \"correct\" and \"total\" counters.\n",
    "\n",
    "How would you characterize the calibration for the Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(pred) <= 0.5000000000000    total =   1    accuracy = 0.000\n",
      "p(pred) <= 0.9000000000000    total =  31    accuracy = 0.387\n",
      "p(pred) <= 0.9990000000000    total =  75    accuracy = 0.413\n",
      "p(pred) <= 0.9999900000000    total =  62    accuracy = 0.500\n",
      "p(pred) <= 0.9999999000000    total =  52    accuracy = 0.615\n",
      "p(pred) <= 0.9999999990000    total =  55    accuracy = 0.745\n",
      "p(pred) <= 0.9999999999900    total =  41    accuracy = 0.707\n",
      "p(pred) <= 0.9999999999999    total =  53    accuracy = 0.811\n",
      "p(pred) <= 1.0000000000000    total = 630    accuracy = 0.948\n",
      "\n",
      "Checks\n",
      "Sum of Totals by Bin: 1000\n",
      "Count of Corrects = 816 which Equals the Accuracy Score when Divided by 1000 of 0.816\n"
     ]
    }
   ],
   "source": [
    "def P11(buckets, correct, total):\n",
    "\n",
    "    # Train a BernoulliNB model with mini_train_data and predict on dev_data\n",
    "    \n",
    "    X = mini_train_data\n",
    "    y = mini_train_labels\n",
    "    clf = BernoulliNB(alpha=0.5,binarize=0.000001)\n",
    "    clf.fit(X, y)\n",
    "    y_predict = clf.predict(dev_data)\n",
    "    \n",
    "    #generate the 1000 length probability matrix for each digit 10 wide\n",
    "    prob = clf.predict_proba(dev_data)    \n",
    "\n",
    "    # generate a 1000 length vector of the best probability for each predicition\n",
    "    for i in range (len(y_predict)): max_prob [i] = prob[i][y_predict[i]]      \n",
    "    \n",
    "    # bucket the 1000 probabilities into the probability buckets, bins is the bin number each prob is in.\n",
    "    bins = np.digitize(max_prob, buckets, right=True)     \n",
    "    \n",
    "    # accumulate totals for the 9 bins\n",
    "    for i in bins: total[i] += 1       \n",
    "\n",
    "     # accumulate correct counts for the 9 bins   \n",
    "    for i in range (len(y_predict)): \n",
    "        if y_predict[i] == dev_labels[i]: \n",
    "            correct[bins[i]] += 1\n",
    "               \n",
    "### MAIN ###\n",
    "\n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "max_prob = [0 for i in dev_labels]\n",
    "\n",
    "P11(buckets, correct, total)\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "    accuracy = 0.0\n",
    "    if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "    print ('p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy))\n",
    "\n",
    "print() \n",
    "print(\"Checks\")\n",
    "sum = 0    \n",
    "for n in total: sum = sum + n\n",
    "print(\"Sum of Totals by Bin:\", sum)\n",
    "\n",
    "sum = 0    \n",
    "for n in correct: sum = sum + n\n",
    "print(\"Count of Corrects =\", sum, \"which Equals the Accuracy Score when Divided by 1000 of\", clf.score(dev_data, dev_labels))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:I would characterized the calibration of this model to be weakly calibrated.  There is definitely a correlation between posterior probability and the accuracy so it is not poorly calibrated. It is not strongly calibrated as when the posterior probability is in the 90-99.9% range, the accuracy is only 41.3% and even lower in the 50-90% range.  So I believe it to be weakly calibrated as when the posterior probability of the model increases, so does the accuracy in all cases except one (the step between bin 6 and 7 where accuracy goes down from .745 to .707.)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) EXTRA CREDIT\n",
    "\n",
    "Try designing extra features to see if you can improve the performance of Naive Bayes on the dev set. Here are a few ideas to get you started:\n",
    "- Try summing the pixel values in each row and each column.\n",
    "- Try counting the number of enclosed regions; 8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0.\n",
    "\n",
    "Make sure you comment your code well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model accuracy with column sum feature is: 0.829\n"
     ]
    }
   ],
   "source": [
    "def P12():\n",
    "\n",
    "    # 4s and 9s were the most confused digits in this data set. This is due to the similarity in the shape of the 2 digits.\n",
    "    # There is one key difference in the shape; the 4 will be open on the top where the 9 would have a continuous line.  \n",
    "    # That should result in the 9 having more pixel values in those columns.  This function will try and improve accuracy \n",
    "    # by focusing on that difference and summing the column pixel values of each digit as a new piece of information and \n",
    "    # storing that data in a new row 29 as the sum of each column.  Our matrix size is now 29X28.  The function accepts a \n",
    "    # data set parameter and returns a modified data set. \n",
    "    \n",
    "    def distiguish_4_and_9(data_set):\n",
    "        \n",
    "        # This function initializes an array, stores the original pixels and adds a new 29th row of summed columns.\n",
    "        \n",
    "        enhanced_data_set = np.zeros((len(data_set), 29, 28))\n",
    "        for i in range(len(data_set)):\n",
    "            enhanced_data_set[i][0:28] = data_set[i].reshape(28,28)\n",
    "            enhanced_data_set[i][28] = np.sum(data_set[i].reshape(28,28), axis=0)\n",
    "    \n",
    "        return enhanced_data_set\n",
    "    \n",
    "\n",
    "    #Build new versions of training and development data that include the new column sum feature \n",
    "    enhanced_mini_data = distiguish_4_and_9(mini_train_data).reshape(1000,812)\n",
    "    enhanced_dev_data = distiguish_4_and_9(dev_data).reshape(1000,812)\n",
    "\n",
    "    # Fit the BernoulliNB model on the enhanced data sets\n",
    "    clf = BernoulliNB(alpha=0.01, binarize=.5)\n",
    "    clf.fit(enhanced_mini_data, mini_train_labels)\n",
    "    print ('New model accuracy with column sum feature is: {:.3f}'.format(clf.score(enhanced_dev_data, dev_labels)))\n",
    "\n",
    "### Main ### \n",
    "\n",
    "P12()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
